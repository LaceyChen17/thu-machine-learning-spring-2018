{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = './a9a'\n",
    "TEST_DATA = './a9a.t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(path):\n",
    "    \"\"\"Parser for the dataset\n",
    "    args:\n",
    "        path: path for train/test dataset\n",
    "    return:\n",
    "        pandas dataframe\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(path, 'r') as f:\n",
    "        line = f.readline()\n",
    "        while line != None and line != '':\n",
    "            sample = dict()\n",
    "            line = line.split()\n",
    "            sample['label'] = int(line[0])\n",
    "            for feat in line[1:]:\n",
    "                feat_id, feat_value = feat.split(':')\n",
    "                sample[feat_id] = float(feat_value)  \n",
    "            data.append(sample)\n",
    "            line = f.readline()\n",
    "    data = pd.DataFrame(data).fillna(0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = parser(TRAIN_DATA)\n",
    "test = parser(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = train.columns.values.tolist()\n",
    "test_cols = test.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between train and test: {'123'}\n"
     ]
    }
   ],
   "source": [
    "print('Difference between train and test: {}'.format(set(train_cols) - set(test_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['123'] = 0 # impute missing data \n",
    "train['intercept'] = 1 # add a dim for intercept \n",
    "test['intercept'] = 1 # add a dim for intercept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[train.columns] # enusure the corresponding columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.label == -1, 'label'] = 0\n",
    "test.loc[test.label == -1, 'label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', 'intercept']\n"
     ]
    }
   ],
   "source": [
    "feat_cols = train.columns.tolist()\n",
    "feat_cols.remove('label')\n",
    "print('Features: ', feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "for idx, feat in enumerate(feat_cols):\n",
    "    if feat == '123':\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"numerically stable sigmoid\"\"\"\n",
    "    return np.exp(-np.logaddexp(0, -x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IRLS4LR(object):\n",
    "    def __init__(self, max_iter=1e3, tol=1e-3, l2_penalty=False):\n",
    "        \"\"\"the iteration will stop when ``max{|delta_i | i = 1, ..., n} <= tol``\n",
    "        where ``delta_i`` is the i-th component of the delta w.\"\"\"\n",
    "        self.weight = None\n",
    "        self.l2_norms = []\n",
    "        self.train_accs= []\n",
    "        self.test_accs = []\n",
    "        self.num_iteration = 0\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.l2_penalty = l2_penalty\n",
    "        \n",
    "    def fit(self, X, y, X_test, y_test):\n",
    "        \"\"\"Fit lr model on (X, y) and evaluate on (X_test, y_test)\"\"\"\n",
    "        num_samples, num_features = X.shape\n",
    "        converged = False\n",
    "        self.l2_norms = []\n",
    "        self.train_accs = []\n",
    "        self.test_accs = []\n",
    "        self.num_iteration = 0\n",
    "        self.weight = np.zeros(num_features)\n",
    "        while not converged:\n",
    "            self.num_iteration += 1\n",
    "            mu = self.predict(X)[0]\n",
    "            R = np.diag(np.multiply(mu, (1 - mu)))\n",
    "            H = np.matmul(np.matmul(X.transpose(), R), X)\n",
    "            g = np.matmul(X.transpose(), mu - y)\n",
    "            if self.l2_penalty:\n",
    "                H = H + self.l2_penalty * np.identity(H.shape[0])\n",
    "                g = g + self.l2_penalty * self.weight\n",
    "            delta = - np.matmul(np.linalg.pinv(H), g) # psuedo inverse for singular matrices\n",
    "            self.weight += delta\n",
    "            \n",
    "            # evaluate\n",
    "            y_pred = self.predict(X)[1]\n",
    "            y_test_pred = self.predict(X_test)[1]\n",
    "            self.l2_norms.append(np.linalg.norm(self.weight))\n",
    "            self.train_accs.append(accuracy_score(y, y_pred))\n",
    "            self.test_accs.append(accuracy_score(y_test, y_test_pred))\n",
    "            print('Iteration {}: Train Accuracy {}, Test Accuracy {}'.format(self.num_iteration, \n",
    "                                                                             self.train_accs[-1],\n",
    "                                                                             self.test_accs[-1]))\n",
    "            if np.linalg.norm(delta) < self.tol or self.num_iteration > self.max_iter:\n",
    "                converged = True\n",
    "                \n",
    "    def predict(self, X):\n",
    "        mu = sigmoid(np.matmul(X, self.weight))\n",
    "        y_pred = np.zeros_like(mu)\n",
    "        y_pred[mu > 0.5] = 1\n",
    "        return mu, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = IRLS4LR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (32561, 124), Test (16281, 124)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.loc[:, feat_cols].values\n",
    "y_train = train['label'].values\n",
    "X_test = test.loc[:, feat_cols].values\n",
    "y_test = test['label'].values\n",
    "print('Train {}, Test {}'.format(X_train.shape, X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6281"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16281 * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Train Accuracy 0.8452750222659009, Test Accuracy 0.8452797739696579\n",
      "Iteration 2: Train Accuracy 0.8481619114892048, Test Accuracy 0.8481665745347338\n",
      "Iteration 3: Train Accuracy 0.8494517981634471, Test Accuracy 0.8493950003071065\n",
      "Iteration 4: Train Accuracy 0.8493289518135192, Test Accuracy 0.849640685461581\n",
      "Iteration 5: Train Accuracy 0.8491139707011456, Test Accuracy 0.8499477919046742\n",
      "Iteration 6: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 7: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 8: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 9: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 10: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 11: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 12: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 13: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 14: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 15: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 16: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 17: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 18: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 19: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 20: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 21: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 22: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 23: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 24: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 25: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 26: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 27: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 28: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n",
      "Iteration 29: Train Accuracy 0.8491446822886275, Test Accuracy 0.8499477919046742\n"
     ]
    }
   ],
   "source": [
    "solver.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.91309376972329"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.l2_norms[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv(X, y, n_fold=5, l2_penalty=0.01):\n",
    "    \"\"\"Run K fold cross validation of LR\n",
    "    return:\n",
    "        cv_train_acc, cv_test_acc\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_fold)\n",
    "    cv_train_accs, cv_test_accs = [], []\n",
    "    for idx, (cv_train, cv_test) in enumerate(kf.split(X)):\n",
    "        print('CV Fold {}'.format(idx))\n",
    "        X_train, y_train = X[cv_train, :], y[cv_train]\n",
    "        X_test, y_test = X[cv_test, :], y[cv_test]\n",
    "        solver = IRLS4LR(l2_penalty = l2_penalty)\n",
    "        solver.fit(X_train, y_train, X_test, y_test)\n",
    "        cv_train_accs.append(solver.train_accs[-1])\n",
    "        cv_test_accs.append(solver.test_accs[-1])\n",
    "    return np.mean(cv_train_accs), np.mean(cv_test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Fold 0\n",
      "Iteration 1: Train Accuracy 0.8467444717444718, Test Accuracy 0.841087056655919\n",
      "Iteration 2: Train Accuracy 0.8495085995085995, Test Accuracy 0.8440042990941194\n",
      "Iteration 3: Train Accuracy 0.8511210073710074, Test Accuracy 0.8440042990941194\n",
      "Iteration 4: Train Accuracy 0.851044226044226, Test Accuracy 0.844311377245509\n",
      "Iteration 5: Train Accuracy 0.8507371007371007, Test Accuracy 0.8453861507753724\n",
      "Iteration 6: Train Accuracy 0.8506603194103194, Test Accuracy 0.8455396898510671\n",
      "Iteration 7: Train Accuracy 0.8506603194103194, Test Accuracy 0.8455396898510671\n",
      "Iteration 8: Train Accuracy 0.8506603194103194, Test Accuracy 0.8455396898510671\n",
      "Iteration 9: Train Accuracy 0.8506603194103194, Test Accuracy 0.8455396898510671\n",
      "Iteration 10: Train Accuracy 0.8506603194103194, Test Accuracy 0.8455396898510671\n",
      "CV Fold 1\n",
      "Iteration 1: Train Accuracy 0.8454067334638565, Test Accuracy 0.8452088452088452\n",
      "Iteration 2: Train Accuracy 0.8474797497024837, Test Accuracy 0.847972972972973\n",
      "Iteration 3: Train Accuracy 0.8496295443203195, Test Accuracy 0.847512285012285\n",
      "Iteration 4: Train Accuracy 0.850282160543591, Test Accuracy 0.8488943488943489\n",
      "Iteration 5: Train Accuracy 0.8502437713539868, Test Accuracy 0.8476658476658476\n",
      "Iteration 6: Train Accuracy 0.8501669929747783, Test Accuracy 0.8476658476658476\n",
      "Iteration 7: Train Accuracy 0.8501669929747783, Test Accuracy 0.8476658476658476\n",
      "Iteration 8: Train Accuracy 0.8501669929747783, Test Accuracy 0.8476658476658476\n",
      "Iteration 9: Train Accuracy 0.8501669929747783, Test Accuracy 0.8476658476658476\n",
      "Iteration 10: Train Accuracy 0.8501669929747783, Test Accuracy 0.8476658476658476\n",
      "CV Fold 2\n",
      "Iteration 1: Train Accuracy 0.8448308956197935, Test Accuracy 0.8488943488943489\n",
      "Iteration 2: Train Accuracy 0.8479020307881301, Test Accuracy 0.847512285012285\n",
      "Iteration 3: Train Accuracy 0.8491304848554647, Test Accuracy 0.8496621621621622\n",
      "Iteration 4: Train Accuracy 0.849744711889132, Test Accuracy 0.8488943488943489\n",
      "Iteration 5: Train Accuracy 0.8492840416138815, Test Accuracy 0.8495085995085995\n",
      "Iteration 6: Train Accuracy 0.84936081999309, Test Accuracy 0.8496621621621622\n",
      "Iteration 7: Train Accuracy 0.84936081999309, Test Accuracy 0.8496621621621622\n",
      "Iteration 8: Train Accuracy 0.84936081999309, Test Accuracy 0.8496621621621622\n",
      "Iteration 9: Train Accuracy 0.84936081999309, Test Accuracy 0.8496621621621622\n",
      "Iteration 10: Train Accuracy 0.84936081999309, Test Accuracy 0.8496621621621622\n",
      "CV Fold 3\n",
      "Iteration 1: Train Accuracy 0.8448692848093977, Test Accuracy 0.8424447174447175\n",
      "Iteration 2: Train Accuracy 0.8483627010633805, Test Accuracy 0.8452088452088452\n",
      "Iteration 3: Train Accuracy 0.8489001497178394, Test Accuracy 0.8461302211302212\n",
      "Iteration 4: Train Accuracy 0.8492072632346731, Test Accuracy 0.8473587223587223\n",
      "Iteration 5: Train Accuracy 0.8491304848554647, Test Accuracy 0.8476658476658476\n",
      "Iteration 6: Train Accuracy 0.8490537064762563, Test Accuracy 0.8476658476658476\n",
      "Iteration 7: Train Accuracy 0.8490537064762563, Test Accuracy 0.8476658476658476\n",
      "Iteration 8: Train Accuracy 0.8490537064762563, Test Accuracy 0.8476658476658476\n",
      "Iteration 9: Train Accuracy 0.8490537064762563, Test Accuracy 0.8476658476658476\n",
      "Iteration 10: Train Accuracy 0.8490537064762563, Test Accuracy 0.8476658476658476\n",
      "CV Fold 4\n",
      "Iteration 1: Train Accuracy 0.8465584091519828, Test Accuracy 0.8430589680589681\n",
      "Iteration 2: Train Accuracy 0.8489001497178394, Test Accuracy 0.8481265356265356\n",
      "Iteration 3: Train Accuracy 0.8489385389074436, Test Accuracy 0.8492014742014742\n",
      "Iteration 4: Train Accuracy 0.8488233713386311, Test Accuracy 0.8490479115479116\n",
      "Iteration 5: Train Accuracy 0.8488617605282353, Test Accuracy 0.8485872235872236\n",
      "Iteration 6: Train Accuracy 0.8488617605282353, Test Accuracy 0.8487407862407862\n",
      "Iteration 7: Train Accuracy 0.8488617605282353, Test Accuracy 0.8487407862407862\n",
      "Iteration 8: Train Accuracy 0.8488617605282353, Test Accuracy 0.8487407862407862\n",
      "Iteration 9: Train Accuracy 0.8488617605282353, Test Accuracy 0.8487407862407862\n",
      "Iteration 10: Train Accuracy 0.8488617605282353, Test Accuracy 0.8487407862407862\n",
      "Iteration 11: Train Accuracy 0.8488617605282353, Test Accuracy 0.8487407862407862\n",
      "l2_penalty=0.01: cv train acc 0.8496207198765358, cv test acc 0.8478548667171422\n",
      "CV Fold 0\n",
      "Iteration 1: Train Accuracy 0.8467828624078624, Test Accuracy 0.841087056655919\n",
      "Iteration 2: Train Accuracy 0.8495469901719902, Test Accuracy 0.8440042990941194\n",
      "Iteration 3: Train Accuracy 0.8511977886977887, Test Accuracy 0.8444649163212038\n",
      "Iteration 4: Train Accuracy 0.8510058353808354, Test Accuracy 0.8444649163212038\n",
      "Iteration 5: Train Accuracy 0.8507754914004914, Test Accuracy 0.8455396898510671\n",
      "Iteration 6: Train Accuracy 0.8507371007371007, Test Accuracy 0.8456932289267619\n",
      "Iteration 7: Train Accuracy 0.8507371007371007, Test Accuracy 0.8456932289267619\n",
      "Iteration 8: Train Accuracy 0.8507371007371007, Test Accuracy 0.8456932289267619\n",
      "CV Fold 1\n",
      "Iteration 1: Train Accuracy 0.8453683442742523, Test Accuracy 0.8452088452088452\n",
      "Iteration 2: Train Accuracy 0.8474029713232754, Test Accuracy 0.8481265356265356\n",
      "Iteration 3: Train Accuracy 0.8496295443203195, Test Accuracy 0.847512285012285\n",
      "Iteration 4: Train Accuracy 0.8502053821643825, Test Accuracy 0.8487407862407862\n",
      "Iteration 5: Train Accuracy 0.8502437713539868, Test Accuracy 0.8476658476658476\n",
      "Iteration 6: Train Accuracy 0.8504357173020077, Test Accuracy 0.8476658476658476\n",
      "Iteration 7: Train Accuracy 0.8504357173020077, Test Accuracy 0.8476658476658476\n",
      "Iteration 8: Train Accuracy 0.8504357173020077, Test Accuracy 0.8476658476658476\n",
      "CV Fold 2\n",
      "Iteration 1: Train Accuracy 0.8448692848093977, Test Accuracy 0.8488943488943489\n",
      "Iteration 2: Train Accuracy 0.8479020307881301, Test Accuracy 0.8476658476658476\n",
      "Iteration 3: Train Accuracy 0.8490920956658605, Test Accuracy 0.8496621621621622\n",
      "Iteration 4: Train Accuracy 0.8496295443203195, Test Accuracy 0.8487407862407862\n",
      "Iteration 5: Train Accuracy 0.8493992091826942, Test Accuracy 0.8495085995085995\n",
      "Iteration 6: Train Accuracy 0.8494375983722984, Test Accuracy 0.8496621621621622\n",
      "Iteration 7: Train Accuracy 0.8494375983722984, Test Accuracy 0.8496621621621622\n",
      "Iteration 8: Train Accuracy 0.8494375983722984, Test Accuracy 0.8496621621621622\n",
      "CV Fold 3\n",
      "Iteration 1: Train Accuracy 0.8449460631886061, Test Accuracy 0.8425982800982801\n",
      "Iteration 2: Train Accuracy 0.8483243118737763, Test Accuracy 0.8452088452088452\n",
      "Iteration 3: Train Accuracy 0.8488617605282353, Test Accuracy 0.8459766584766585\n",
      "Iteration 4: Train Accuracy 0.8492456524242773, Test Accuracy 0.8476658476658476\n",
      "Iteration 5: Train Accuracy 0.8491688740450689, Test Accuracy 0.847972972972973\n",
      "Iteration 6: Train Accuracy 0.8490920956658605, Test Accuracy 0.847972972972973\n",
      "Iteration 7: Train Accuracy 0.8490920956658605, Test Accuracy 0.847972972972973\n",
      "Iteration 8: Train Accuracy 0.8490920956658605, Test Accuracy 0.847972972972973\n",
      "CV Fold 4\n",
      "Iteration 1: Train Accuracy 0.8465200199623786, Test Accuracy 0.8429054054054054\n",
      "Iteration 2: Train Accuracy 0.8488233713386311, Test Accuracy 0.8478194103194103\n",
      "Iteration 3: Train Accuracy 0.8489769280970478, Test Accuracy 0.8492014742014742\n",
      "Iteration 4: Train Accuracy 0.849015317286652, Test Accuracy 0.8488943488943489\n",
      "Iteration 5: Train Accuracy 0.8489385389074436, Test Accuracy 0.8487407862407862\n",
      "Iteration 6: Train Accuracy 0.8489385389074436, Test Accuracy 0.8488943488943489\n",
      "Iteration 7: Train Accuracy 0.8489385389074436, Test Accuracy 0.8488943488943489\n",
      "Iteration 8: Train Accuracy 0.8489385389074436, Test Accuracy 0.8488943488943489\n",
      "Iteration 9: Train Accuracy 0.8489385389074436, Test Accuracy 0.8488943488943489\n",
      "l2_penalty=0.1: cv train acc 0.8497282101969421, cv test acc 0.8479777121244186\n",
      "CV Fold 0\n",
      "Iteration 1: Train Accuracy 0.8467444717444718, Test Accuracy 0.841701212958698\n",
      "Iteration 2: Train Accuracy 0.8495853808353808, Test Accuracy 0.844311377245509\n",
      "Iteration 3: Train Accuracy 0.8506987100737101, Test Accuracy 0.8441578381698143\n",
      "Iteration 4: Train Accuracy 0.8508522727272727, Test Accuracy 0.8450790726239829\n",
      "Iteration 5: Train Accuracy 0.8506603194103194, Test Accuracy 0.8456932289267619\n",
      "Iteration 6: Train Accuracy 0.850583538083538, Test Accuracy 0.8456932289267619\n",
      "Iteration 7: Train Accuracy 0.850583538083538, Test Accuracy 0.8456932289267619\n",
      "CV Fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Train Accuracy 0.8451380091366272, Test Accuracy 0.8453624078624079\n",
      "Iteration 2: Train Accuracy 0.8472878037544628, Test Accuracy 0.8482800982800983\n",
      "Iteration 3: Train Accuracy 0.8493992091826942, Test Accuracy 0.8481265356265356\n",
      "Iteration 4: Train Accuracy 0.8502437713539868, Test Accuracy 0.8482800982800983\n",
      "Iteration 5: Train Accuracy 0.8503589389227993, Test Accuracy 0.847051597051597\n",
      "Iteration 6: Train Accuracy 0.8503973281124035, Test Accuracy 0.847051597051597\n",
      "Iteration 7: Train Accuracy 0.8503973281124035, Test Accuracy 0.847051597051597\n",
      "CV Fold 2\n",
      "Iteration 1: Train Accuracy 0.8449076739990019, Test Accuracy 0.8493550368550369\n",
      "Iteration 2: Train Accuracy 0.8477868632193174, Test Accuracy 0.847512285012285\n",
      "Iteration 3: Train Accuracy 0.8487849821490269, Test Accuracy 0.8490479115479116\n",
      "Iteration 4: Train Accuracy 0.8492456524242773, Test Accuracy 0.8495085995085995\n",
      "Iteration 5: Train Accuracy 0.8491304848554647, Test Accuracy 0.8490479115479116\n",
      "Iteration 6: Train Accuracy 0.8491688740450689, Test Accuracy 0.8490479115479116\n",
      "Iteration 7: Train Accuracy 0.8491688740450689, Test Accuracy 0.8490479115479116\n",
      "Iteration 8: Train Accuracy 0.8491688740450689, Test Accuracy 0.8490479115479116\n",
      "CV Fold 3\n",
      "Iteration 1: Train Accuracy 0.8448308956197935, Test Accuracy 0.8427518427518428\n",
      "Iteration 2: Train Accuracy 0.8479788091673385, Test Accuracy 0.8453624078624079\n",
      "Iteration 3: Train Accuracy 0.8489385389074436, Test Accuracy 0.8464373464373465\n",
      "Iteration 4: Train Accuracy 0.8491304848554647, Test Accuracy 0.847972972972973\n",
      "Iteration 5: Train Accuracy 0.8489385389074436, Test Accuracy 0.8481265356265356\n",
      "Iteration 6: Train Accuracy 0.8488617605282353, Test Accuracy 0.8481265356265356\n",
      "Iteration 7: Train Accuracy 0.8488617605282353, Test Accuracy 0.8481265356265356\n",
      "CV Fold 4\n",
      "Iteration 1: Train Accuracy 0.8462512956351491, Test Accuracy 0.8427518427518428\n",
      "Iteration 2: Train Accuracy 0.8488617605282353, Test Accuracy 0.8476658476658476\n",
      "Iteration 3: Train Accuracy 0.8483627010633805, Test Accuracy 0.8485872235872236\n",
      "Iteration 4: Train Accuracy 0.8486698145802142, Test Accuracy 0.8492014742014742\n",
      "Iteration 5: Train Accuracy 0.8486698145802142, Test Accuracy 0.8490479115479116\n",
      "Iteration 6: Train Accuracy 0.84863142539061, Test Accuracy 0.8492014742014742\n",
      "Iteration 7: Train Accuracy 0.84863142539061, Test Accuracy 0.8492014742014742\n",
      "l2_penalty=1: cv train acc 0.8495285852319711, cv test acc 0.847824149470856\n",
      "CV Fold 0\n",
      "Iteration 1: Train Accuracy 0.8455927518427518, Test Accuracy 0.8412405957316137\n",
      "Iteration 2: Train Accuracy 0.8490863022113022, Test Accuracy 0.8438507600184247\n",
      "Iteration 3: Train Accuracy 0.8497389434889435, Test Accuracy 0.844925533548288\n",
      "Iteration 4: Train Accuracy 0.8503915847665847, Test Accuracy 0.8441578381698143\n",
      "Iteration 5: Train Accuracy 0.8503531941031941, Test Accuracy 0.844311377245509\n",
      "Iteration 6: Train Accuracy 0.8503531941031941, Test Accuracy 0.8441578381698143\n",
      "Iteration 7: Train Accuracy 0.8503531941031941, Test Accuracy 0.8441578381698143\n",
      "CV Fold 1\n",
      "Iteration 1: Train Accuracy 0.8443318361549388, Test Accuracy 0.8452088452088452\n",
      "Iteration 2: Train Accuracy 0.846788744289608, Test Accuracy 0.8487407862407862\n",
      "Iteration 3: Train Accuracy 0.848439479442589, Test Accuracy 0.8478194103194103\n",
      "Iteration 4: Train Accuracy 0.84936081999309, Test Accuracy 0.8478194103194103\n",
      "Iteration 5: Train Accuracy 0.8493224308034857, Test Accuracy 0.847051597051597\n",
      "Iteration 6: Train Accuracy 0.8492840416138815, Test Accuracy 0.8472051597051597\n",
      "Iteration 7: Train Accuracy 0.8492840416138815, Test Accuracy 0.8472051597051597\n",
      "CV Fold 2\n",
      "Iteration 1: Train Accuracy 0.844370225344543, Test Accuracy 0.847972972972973\n",
      "Iteration 2: Train Accuracy 0.8471726361856501, Test Accuracy 0.8472051597051597\n",
      "Iteration 3: Train Accuracy 0.8485930362010058, Test Accuracy 0.8481265356265356\n",
      "Iteration 4: Train Accuracy 0.8482859226841721, Test Accuracy 0.8490479115479116\n",
      "Iteration 5: Train Accuracy 0.8481323659257554, Test Accuracy 0.8488943488943489\n",
      "Iteration 6: Train Accuracy 0.8480939767361511, Test Accuracy 0.8490479115479116\n",
      "Iteration 7: Train Accuracy 0.8480939767361511, Test Accuracy 0.8490479115479116\n",
      "CV Fold 3\n",
      "Iteration 1: Train Accuracy 0.8448308956197935, Test Accuracy 0.8425982800982801\n",
      "Iteration 2: Train Accuracy 0.847710084840109, Test Accuracy 0.8442874692874693\n",
      "Iteration 3: Train Accuracy 0.8481323659257554, Test Accuracy 0.8458230958230958\n",
      "Iteration 4: Train Accuracy 0.8479404199777343, Test Accuracy 0.8485872235872236\n",
      "Iteration 5: Train Accuracy 0.8479404199777343, Test Accuracy 0.8487407862407862\n",
      "Iteration 6: Train Accuracy 0.8479404199777343, Test Accuracy 0.8485872235872236\n",
      "Iteration 7: Train Accuracy 0.8479404199777343, Test Accuracy 0.8485872235872236\n",
      "CV Fold 4\n",
      "Iteration 1: Train Accuracy 0.8454067334638565, Test Accuracy 0.8432125307125307\n",
      "Iteration 2: Train Accuracy 0.8479788091673385, Test Accuracy 0.8478194103194103\n",
      "Iteration 3: Train Accuracy 0.8480939767361511, Test Accuracy 0.8487407862407862\n",
      "Iteration 4: Train Accuracy 0.8480939767361511, Test Accuracy 0.8481265356265356\n",
      "Iteration 5: Train Accuracy 0.8478252524089216, Test Accuracy 0.8476658476658476\n",
      "Iteration 6: Train Accuracy 0.8477868632193174, Test Accuracy 0.8476658476658476\n",
      "Iteration 7: Train Accuracy 0.8477868632193174, Test Accuracy 0.8476658476658476\n",
      "l2_penalty=10: cv train acc 0.8486916991300557, cv test acc 0.8473327961351913\n"
     ]
    }
   ],
   "source": [
    "for l2_penalty in [0.01, 0.1, 1, 10]:\n",
    "    cv_train_acc, cv_test_acc = cv(X_train, y_train, l2_penalty=l2_penalty)\n",
    "    print('l2_penalty={}: cv train acc {}, cv test acc {}'.format(l2_penalty, cv_train_acc, cv_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Train Accuracy 0.8453057338533829, Test Accuracy 0.8453411952582766\n",
      "Iteration 2: Train Accuracy 0.8482233346641688, Test Accuracy 0.8481665745347338\n",
      "Iteration 3: Train Accuracy 0.849513221338411, Test Accuracy 0.8493950003071065\n",
      "Iteration 4: Train Accuracy 0.8493596634010012, Test Accuracy 0.8497635280388183\n",
      "Iteration 5: Train Accuracy 0.8490832591136636, Test Accuracy 0.8499477919046742\n",
      "Iteration 6: Train Accuracy 0.8491139707011456, Test Accuracy 0.8498863706160555\n",
      "Iteration 7: Train Accuracy 0.8491139707011456, Test Accuracy 0.8498863706160555\n",
      "Iteration 8: Train Accuracy 0.8491139707011456, Test Accuracy 0.8498863706160555\n"
     ]
    }
   ],
   "source": [
    "l2_solver = IRLS4LR(l2_penalty=0.1)\n",
    "l2_solver.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.597460608945966"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.weight[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.906510023186412"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_solver.l2_norms[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " l2_penalty=100: cv train acc 0.8451061134501477, cv test acc 0.844415148157663\n",
    " l2_penalty=10: cv train acc 0.8486916991300557, cv test acc 0.8473327961351913\n",
    " l2_penalty=1: cv train acc 0.8495285852319711, cv test acc 0.847824149470856\n",
    " l2_penalty=0.8: cv train acc 0.8496283985987286, cv test acc 0.8478241447552826\n",
    " l2_penalty=0.6: cv train acc 0.8496591105399265, cv test acc 0.8479162823474201\n",
    " l2_penalty=0.4: cv train acc 0.8497819568309319, cv test acc 0.8478855698167076\n",
    " l2_penalty=0.2: cv train acc 0.8497742775192245, cv test acc 0.8479777121244186\n",
    " l2_penalty=0.1: cv train acc 0.8497282101969421, cv test acc 0.8479777121244186\n",
    " l2_penalty=0.06: cv train acc 0.849720532064264, cv test acc 0.8479469995937061\n",
    " l2_penalty=0.04: cv train acc 0.8496974985505015, cv test acc 0.8478855792478546   \n",
    " l2_penalty=0.02: cv train acc 0.8496207198765358, cv test acc 0.8478548667171422\n",
    " l2_penalty=0.01: cv train acc 0.8496207198765358, cv test acc 0.8478548667171422\n",
    " l2_penalty=0.001: cv train acc 0.8496283977144566, cv test acc 0.8478241589020034\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'test accuracy')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(solver.test_accs, 'b^', label='LR')\n",
    "plt.plot(l2_solver.test_accs, 'r^', label='L2 regularized LR')\n",
    "plt.xlabel('num of iterations')\n",
    "plt.ylabel('test accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAb3Aso7JDC6kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9eb3445048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'l2 norm of weights')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(solver.l2_norms, 'bs', label='LR')\n",
    "plt.plot(l2_solver.l2_norms, 'rs', label='L2 regularized LR')\n",
    "plt.xlabel('num of iterations')\n",
    "plt.ylabel('l2 norm of weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAHDRJREFUeJzt3XuUXWWZ5/HvD4iGBBxuSYUmQgUN\nRK5FUtGkEZtLo9zBFmgzQWmbkdAgYqBRZM0gs4RZqBikRcYORAgQaVTABBoZICagjsFUhQQIl4Ax\nDMnKjXAxJQZC8swfZ1eoJHWqdlWdfU6dvX+ftc6qc959e3Y2nOe8737fdysiMDOz4tqh1gGYmVlt\nORGYmRWcE4GZWcE5EZiZFZwTgZlZwTkRmJkVnBOBmVnBORGYmRWcE4GZWcHtVOsA0thrr72isbGx\n1mGYmdWV1tbW1yJiSHfr1UUiaGxspKWlpdZhmJnVFUmvpFnPTUNmZgXnRGBmVnBOBGZmBVcX9wg6\ns3HjRpYvX86GDRtqHYplaODAgQwfPpwBAwbUOhSz3KrbRLB8+XJ23XVXGhsbkVTrcCwDEcG6detY\nvnw5I0aMqHU4ZrlVt01DGzZsYM8993QSyDFJ7Lnnnq71WS4MGwbS9q9hw3q3XiXVbSIAnAQKwNfY\n8mL16nTladerpLpOBGZmtVSLX+9ZcCLog1122WW7squvvpp99tmHpqYmDjroIO6+++4aRGZm1VCL\nX+9ZKEQiqHbWnjx5MgsXLmTmzJlMmjSJjRs3ZnMgM7MKKEQiqFXWHjlyJIMGDeKNN97I9kBmVjF5\nae7piUIkglpZsGABI0eOZOjQobUOxcxSyuqHY0NDuvK061VS3Y4j6M9uuOEGbrvtNpYsWcIDDzxQ\n63DMrB9Ytaqy61WSawQZmDx5MosXL+bee+/lvPPOcz94s5yqxa/3LDgRZOi0006jubmZ6dOn1zoU\nM8vAqlUQsf2rFr/q+6IQiSCrrP32228zfPjwLa8pU6Zst85VV13FlClT2Lx5c98OZmaWkULcI8gq\nO6f5ch8zZgwvvvhiNgGYWcU1NHR+Y7jemnt6ohCJwMwsrXpr1qmEQjQNmVmxFXFsQE84EZhZ7uVl\nKoisZNo0JGkZsB7YBLwXEc2S9gDuARqBZcDZEeGht2ZmNVKNGsExEdEUEc3J5yuA2RExEpidfDYz\nsxqpRdPQ6UB7x/rpwBk1iMHMzBJZJ4IAHpHUKun8pKwhIlYm71cBnXbKknS+pBZJLWvXrs04zN7p\nbBrqKVOmcNBBB3HYYYdx3HHH8corr/SLuLpz0kkn8eabb/bpuHPnzuWUU05JXX700Udz4IEHcvjh\nhzN27FgWLlzYp+ObWe9knQg+GRGjgROBiyR9quPCiAhKyWI7ETE1IpojonnIkCF9i6KKXQaOOOII\nWlpaePrppznzzDP5+te/3uX6EVHTwWbtx3/ooYfYbbfdqn78GTNmsGjRIi688EIuv/zyqh/fiiEv\nU0FkJdNEEBErkr9rgPuBjwOrJe0NkPxdk2UMQFW7DBxzzDEMGjQIgHHjxrF8+fLt1lm2bBkHHngg\nX/ziFznkkEN49dVXeeSRRxg/fjyjR4/mrLPOoq2tDYCHHnqIUaNGMWbMGL761a9u+WV99dVXc/31\n12/Z5yGHHMKyZcu2Ok5bWxvHHXcco0eP5tBDD2XmzJllj9/Y2Mhrr73Gj3/8Y5qammhqamLEiBEc\nc8wxAGXje/jhhxk1ahSjR4/mvvvu6/W/2/jx41mxYkWvt7fi6cnvu7xMBZGVzBKBpMGSdm1/D3wa\neBaYBZybrHYuMDOrGGpt2rRpnHjiiZ0ue+mll7jwwgtZvHgxgwcP5pprruGxxx5jwYIFNDc3M2XK\nFDZs2MCkSZP41a9+RWtrKz1tIhs4cCD3338/CxYsYM6cOVx22WWUKmFbH3+//fbbss0FF1zAwoUL\nmT9/PsOHD+fSSy/ltddeKxvfl7/8ZR544AFaW1tZ1Yf/qx5++GHOOMO3iyw9dwmtnCy7jzYA9ycP\nH98J+GlEPCxpPvAzSecBrwBnZxhDzdx11120tLTw+OOPd7p8v/32Y9y4cQDMmzeP5557jiOPPBKA\nd999l/Hjx/PCCy+w//77M2LECAAmTJjA1KlTU8cQEVx55ZU88cQT7LDDDqxYsYLVyf8lHY/fmUsu\nuYRjjz2WU089lQcffLBsfCNGjGDkyJEAnHPOOT2KD2DixIm8++67tLW1+R6BWY1klggiYilweCfl\n64Djsjpuf/DYY49x7bXX8vjjj/PBD36w03UGDx685X1EcPzxx2/3fOOuvhh32mmnre4tdDbV9YwZ\nM1i7di2tra0MGDCAxsbGLet1PP62br/9dl555RVuuummXseX1owZMxgzZgyXX345F198cZ+al8ys\ndzyyuMKeeuopJk2axKxZs1I/mWzcuHH87ne/4+WXXwbgL3/5C0uWLOHAAw9k6dKlW9r+77nnni3b\nNDY2smDBAqD0JLQ//elP2+33rbfeYujQoQwYMIA5c+ak6sHU2trK9ddfz1133cUOO+zQZXyjRo1i\n2bJl/PGPfwTYLlGkJYlvf/vbzJs3jxdeeKFX+zCz3ivGpHMZTSfYPg11u0svvZSHHnqItrY2zjrr\nLAD23XdfZs2a1eV+hgwZwu23386ECRN45513ALjmmms44IADuPnmmznhhBMYPHgwY8eO3bLN5z73\nOe644w4OPvhgPvGJT3DAAQdst9+JEydy6qmncuihh9Lc3MyoUaO6PaebbrqJ119/fctN4ubmZm69\n9day8U2dOpWTTz6ZQYMGcdRRR7F+/fpO9zt79uyt/q1+/vOfb7V855135rLLLuN73/se06ZN6zZO\nM6sctd887M+am5ujpaVlq7Lnn3+ej33sYzWKqHra2trYZZddiAguuugiRo4cyeTJk2sdVlUV5Vpb\nzwwbVv73nXsDlUhq7TCrQ1luGurnbrnlFpqamjj44IN56623mDRpUq1DMusX3CW0corRNFTHJk+e\nXLgagBWXf+XXRl3XCOqhWcv6xte4WDw2oDbqNhEMHDiQdevW+YsixyKCdevWMXDgwFqHYpZrdds0\nNHz4cJYvX97j0bZWXwYOHLhVbyMzq7y6TQQDBgzYMuLWzMx6r26bhszMrDKcCMys3/B00bVRt01D\nZpY/7iJaG64RmJkVnBOBmWWqig8ItF5yIjCzTHmQWP/nRGBmVnBOBGZmBedEYGZWcE4EZmYF50Rg\nZpnyILH+zwPKzCxTHiTW/7lGYGY95rEB+eJEYGY95rEB+eJEYGZWcE4EZmYF50RgZlZwTgRmZgXn\nRGBmPeaxAfnicQRm1mMeG5AvmdcIJO0o6SlJDyafR0h6UtLLku6R9IGsYzAzs/Kq0TR0CfB8h8/f\nAW6IiI8CbwDnVSEGM0vBA8WKKdNEIGk4cDJwa/JZwLHAL5JVpgNnZBmDmaXngWLFlHWN4AfA14HN\nyec9gTcj4r3k83Jgn4xjMDOzLnSbCCRdIulDKpkmaYGkT6fY7hRgTUS09iYwSedLapHUsnbt2t7s\nwszMUkhTI/jniPgz8Glgd+ALwHUptjsSOE3SMuA/KDUJ3QjsJqm9t9JwYEVnG0fE1IhojojmIUOG\npDicmZn1RppEoOTvScCdEbG4Q1lZEfHNiBgeEY3A54FfR8REYA5wZrLaucDMHkdtZmYVkyYRtEp6\nhFIi+D+SduX9Nv/e+AZwqaSXKd0zmNaHfZlZBXmgWDGlGVB2HtAELI2ItyXtCXypJweJiLnA3OT9\nUuDjPQvTzKrBA8WKKU2N4NGIWBARbwJExDrghmzDMrNK8dgA607ZGoGkgcAgYC9Ju/P+fYEP4S6f\nZnXDYwOsO101DU0Cvgb8DdDK+4ngz8BNGcdlZmZVUjYRRMSNwI2SLo6IH1YxJjMzq6JubxZHxA8l\n/S3Q2HH9iLgjw7jMzKxKuk0Eku4EPgIsBDYlxQE4EZiZ5UCa7qPNwEEREVkHY2aV19DQ+Y1hjw2w\ndmkSwbPAMGBlxrGYWQY8NsC601X30QcoNQHtCjwn6Q/AO+3LI+K07MMzs84MG1b+V76/+K2nuqoR\nXF+1KMysRzw2wCqpq+6jj1czEDMzq400vYbWU2oi6ugtoAW4LJk7yMzM6lSam8U/oPQksZ9SGl38\neUrdSRcAPwGOzio4MzPLXppJ506LiH+PiPUR8eeImAp8JiLuofSgGjMzq2NpEsHbks6WtEPyOhvY\nkCzz2AKzGvBzA6yS0jQNTaT0iMmbKX3xzwPOkbQz8JUMYzOzMtxF1CopzVxDS4FTyyz+bWXDMTOz\nautqQNnXI+K7kn5IJ01AEfHVTCMzKxgPErNa6apG8Hzyt6UagZgVnQeJWa10NaDsgeTvdABJgyLi\n7WoFZmZm1dFtryFJ4yU9B7yQfD5c0s2ZR2ZmZlWRpvvoD4DPAOsAImIR8KksgzIzs+pJkwiIiFe3\nKdrU6YpmZlZ30iSCV5NHVYakAZL+lfdvJJtZhXiQmNVKmgFlF1AaULYPsAJ4BLgoy6DMishdRK1W\n0iSCtoiYmHkkZjnksQFWD1I9qlLSauA3yeu3EfFWtmGZ5YPHBlg96PYeQUR8FJgAPAOcDCyStDDr\nwMzMrDrSPJhmOHAkcBRwOLAYzzFkZpYbaZqG/h8wH/hfEXFBxvGYmVmVpek+egRwB/BfJf1e0h2S\nzutuI0kDJf1B0iJJiyX9z6R8hKQnJb0s6R5JH+jjOZiZWR+kuUewCJgO3Ab8Gvg74KoU+34HODYi\nDgeagBMkjQO+A9yQ3Ht4A+g2qZjVK48NsHqQZq6hFuD3wGcpDST7VETs1912UdKWfByQvAI4FvhF\nUj4dOKMXcZvVhVWrIGL7l7uOWn+S5h7BiRGxtjc7l7Qj0Ap8FPgR8EfgzYh4L1llOaWBamZ1w2MD\nLG/SNA31Kgkk226KiCZgOPBxYFTabSWdL6lFUsvatb0OwaziPDbA8ibVpHN9FRFvAnOA8cBuktpr\nIsMpTVvR2TZTI6I5IpqHDBlSjTDNzAqpbCKQdFbyd0RvdixpiKTdkvc7A8dTuscwBzgzWe1cYGZv\n9m9mZpXRVY3gm8nfe3u5772BOZKepjQO4dGIeBD4BnCppJeBPYFpvdy/mZlVQFc3i9dJegQYIWnW\ntgsj4rSudhwRT1Mag7Bt+VJK9wvMzKwf6CoRnAyMBu4Evl+dcMz6v4aG8r2GzOpRVw+vfxeYJ+lv\nI2KtpF2S8rZy25gVgbuIWt6k6TXUIOkpSpPNPSepVdIhGcdlVlXDhoG0/WvYsFpHZpa9NIlgKnBp\nROwXEfsClyVlZrnhsQFWZGkSweCImNP+ISLmAoMzi8jMzKoqzRQTSyX9D0o3jQHOAZZmF5KZmVVT\nmhrBPwNDgPsojSnYKykzM7Mc6LZGEBFvAF+tQixmZlYDVZlryKy/83MDrMjS3CMwyz2PDbAic43A\ncstjA8zS6bZGkMw+ejHQ2HH97uYaMqs1jw0wSydN09AvKc0Q+gCwOdtwzMys2tIkgg0R8W+ZR2Jm\nZjWRJhHcKOlbwCPAO+2FEbEgs6jMzKxq0iSCQ4EvAMfyftNQJJ/NzKzOpUkEZwH7J9NSm9UNPzfA\nLJ00ieBZYDdgTcaxmFWUxwaYpZMmEewGvCBpPlvfI3D3UTOzHEiTCL6VeRRmPTBsWPkmH9cCzHqu\ny0QgaUfg6og4pkrxmHXLA8XMKqvLKSYiYhOwWdJ/qVI8ZmZWZWmahtqAZyQ9CvylvTAiPDW1mVkO\npEkE9yUvMzPLoTQPppku6QPAAUnRixGxMduwzMysWrqdhlrS0cBLwI+Am4Elkj6VcVxmZfkhMmaV\nlaZp6PvApyPiRQBJBwB3A2OyDMysHHcRNausNA+mGdCeBAAiYgkwILuQrIj8EBmz2klTI2iRdCtw\nV/J5ItCSXUhWRB4bYFY7aRLBvwAXAe3dRX9D6V6BmZnlQJpeQ+8AU5JXapI+DNwBNFCatnpqRNwo\naQ/gHkqPvlwGnB0Rb/QsbDMzq5Q0vYaOlPSopCWSlra/Uuz7PeCyiDgIGAdcJOkg4ApgdkSMBGYn\nn83MrEbSNA1NAyYDrcCmtDuOiJXAyuT9eknPA/sApwNHJ6tNB+YC30gdsZmZVVSaRPBWRPyqLweR\n1AgcATwJNCRJAmAVpaajzrY5HzgfYN999+3L4a0O+CEyZrWTJhHMkfQ9StNM9PiZxZJ2Ae4FvhYR\nf5a0ZVlEhKTobLuImApMBWhubu50HcsPjw0wq500ieATyd/mDmWpnlksaQClJDAjItrnK1otae+I\nWClpb/zks9zycwPM6kOaXkO9ehaBSj/9pwHPR0THHkezgHOB65K/M3uzf+v/PDbArD6kqRH01pHA\nFyhNYb0wKbuSUgL4maTzgFeAszOMwczMupFZIoiI3wIqs/i4rI5rZmY9k2auITMzy7EuE4GkD0n6\nSCflh2UXkpmZVVPZRCDpbOAF4F5JiyWN7bD49qwDs/rn5waY1YeuagRXAmMiogn4EnCnpM8my8q1\n/VvO9WS66FWrIGL7l7uOmvUvXd0s3rF9BHBE/EHSMcCDyWRyHuBVUO4SapY/XdUI1ne8P5AkhaMp\nzRV0cMZxmZlZlXRVI/gXtkkUyeRxJ+C+/2ZmuVE2EUTEojLlG4EZmUVkZmZVVTYRSFpP5/cCRGm+\nuA9lFpWZmVVNVzWCXasZiNUHTxdtlj9ZzjVkOeSun2b54ykmrEdjA8wsf5wIzGMDzArOicDMrOCc\nCMzMCs6JwMys4JwIzMwKzonAPF20WcE5EeSUp4s2s7ScCHLKXULNLC0nAjOzgnMiMDMrOCcCM7OC\ncyIwMys4J4KccpdQM0vLiaCOuEuomWXBiaCOuEuomWXBicDMrOCcCMzMCs6JwMys4DJLBJJ+ImmN\npGc7lO0h6VFJLyV/d8/q+GZmlk6WNYLbgRO2KbsCmB0RI4HZyefCS9sbyF1CzSwLmSWCiHgCeH2b\n4tOB6cn76cAZWR2/nqTtDeQuoWaWhWrfI2iIiJXJ+1VA2d+yks6X1CKpZe3atdWJzsysgGp2szgi\nAogulk+NiOaIaB4yZEgVIzMzK5ZqJ4LVkvYGSP6uqfLxzcxsG9VOBLOAc5P35wIzq3x8MzPbRpbd\nR+8Gfg8cKGm5pPOA64DjJb0E/H3yOZd6Mi+QewOZWS3tlNWOI2JCmUXHZXXM/qQn8wKl7vUzbFjn\nO2ho2H4nWa1rZrnjkcX9QdrqQ0+yS1brmlnuOBH0B/4iNrMaciLIyEqGEWi710o6uUlgZlZDTgQZ\nGUbnv+bLlZuZ1YoTgZlZwTkR9EBPuoRmoif9TLNa18xyJ7Puo3m0cPWwTpt2Vq1uoDR1Ui81NJTv\nvrnVgXpwjKzWNbPccSLogcza/f1FbGY15KahrLi5xczqhGsEWfGvfDOrE64RmJkVnBOBmVnBFT4R\nrNmx8z6ha3b0NKFmVgyFv0cwdHPnPX46LXe7v5nlUOFrBGZmRedEYGZWcE4EZmYF50RgZlZwhU8E\na3bovMdPuXIzs7zJZSLoSZfQoZtWQcR2r6Gb3EPIzIohl4mgR11CzcwKLpeJwMzM0nMiMDMrOCcC\nM7OCcyIwMyu4XCYCdwk1M0svl5POlev6ObTKcZiZ1YNc1gjMzCw9JwIzs4JzIjAzKzgnAjOzgnMi\nMDMrOEVErWPolqS1wCu93Hwv4LUKhtNf5PW8IL/n5vOqP/V+bvtFxJDuVqqLRNAXkloiornWcVRa\nXs8L8ntuPq/6k+dz68hNQ2ZmBedEYGZWcEVIBFNrHUBG8npekN9z83nVnzyf2xa5v0dgZmZdK0KN\nwMzMupDrRCDpBEkvSnpZ0hW1jqdSJC2T9IykhZJaah1PX0j6iaQ1kp7tULaHpEclvZT83b2WMfZG\nmfO6WtKK5LotlHRSLWPsDUkfljRH0nOSFku6JCmv62vWxXnV/TVLI7dNQ5J2BJYAxwPLgfnAhIh4\nrqaBVYCkZUBzRNRz/2YAJH0KaAPuiIhDkrLvAq9HxHVJAt89Ir5Ryzh7qsx5XQ20RcT1tYytLyTt\nDewdEQsk7Qq0AmcA/0QdX7Muzuts6vyapZHnGsHHgZcjYmlEvAv8B3B6jWOybUTEE8Dr2xSfDkxP\n3k+n9D9kXSlzXnUvIlZGxILk/XrgeWAf6vyadXFehZDnRLAP8GqHz8vJz4UN4BFJrZLOr3UwGWiI\niJXJ+1VAnp4o9BVJTydNR3XVfLItSY3AEcCT5OiabXNekKNrVk6eE0GefTIiRgMnAhclzRC5FKW2\ny7y0X/5v4CNAE7AS+H5tw+k9SbsA9wJfi4g/d1xWz9esk/PKzTXrSp4TwQrgwx0+D0/K6l5ErEj+\nrgHup9QMlierkzbb9rbbNTWOpyIiYnVEbIqIzcAt1Ol1kzSA0pfljIi4Lymu+2vW2Xnl5Zp1J8+J\nYD4wUtIISR8APg/MqnFMfSZpcHIzC0mDgU8Dz3a9Vd2ZBZybvD8XmFnDWCqm/Ysy8Vnq8LpJEjAN\neD4ipnRYVNfXrNx55eGapZHbXkMASVevHwA7Aj+JiGtrHFKfSdqfUi0ASs+c/mk9n5eku4GjKc3y\nuBr4FvBL4GfAvpRmnT07IurqxmuZ8zqaUhNDAMuASR3a1euCpE8CvwGeATYnxVdSak+v22vWxXlN\noM6vWRq5TgRmZta9PDcNmZlZCk4EZmYF50RgZlZwTgRmZgXnRGBmVnBOBGbbkDRE0pOSnpJ01DbL\nbpV0UPL+ygof958k/U1nxzLLkruPmm1D0ueBv4+I/9bNem0RsUsP971jRGwqs2wu8K8RUddTi1v9\ncY3A+h1JjZKel3RLMjf8I5J2TpbNldScvN8rmZK7/df0L5O58JdJ+oqkS5Nf9fMk7VHmOL9OJhSb\nLWlfSU3Ad4HTk/nnd95mm7mSmiVdB+ycrDMjWXaOpD8kZf+eTIWOpDZJ35e0CBgv6SpJ8yU9K2mq\nSs4EmoEZ7cfd5lwnqPQMimclfadDPG2SrpW0KDnPhqT8rGTdRZKeqPAlspxxIrD+aiTwo4g4GHgT\n+FyKbQ4B/gEYC1wLvB0RRwC/B77Yyfo/BKZHxGHADODfImIhcBVwT0Q0RcRfOztQRFwB/DVZZ6Kk\njwH/CBwZEU3AJmBisvpg4MmIODwifgvcFBFjk+cU7AycEhG/AFqAidseN2ku+g5wLKVRrmMlndFh\n3/Mi4nDgCeDLSflVwGeS8tNS/NtZgTkRWH/1p+RLGUoPCWlMsc2ciFgfEWuBt4AHkvJnymw/Hvhp\n8v5O4JO9jhaOA8YA8yUtTD7vnyzbRGkys3bHJPcgnqH05X5wN/seC8yNiLUR8R6lpNU+4+y7wIPJ\n+47/Tr8Dbpf0ZUpTrJiVtVOtAzAr450O7zdR+uUM8B7v/4AZ2MU2mzt83kz2/62LUu3im50s29B+\nX0DSQOBmSk+Ye1Wlp5Ztex49sTHev9G3ieQ8I+ICSZ8ATgZaJY2JiHV9OI7lmGsEVm+WUfrlDXBm\nH/f1fynNSgulZpzf9HD7jcnUxQCzgTMlDYUtz/Ddr5Nt2r/0X0vmvu94DuuBXTvZ5g/A3yX3RHak\nNBHa410FJukjEfFkRFwFrGXrKdnNtuIagdWb64GfqfRktv/s474uBm6TdDmlL8sv9XD7qcDTkhYk\n9wn+O6Unx+0AbAQuojQT5xYR8aakWyhNZ7yK0nTp7W4Hfizpr5Sardq3WanSc4DnUKp5/GdEdDfN\n8/ckjUzWnw0s6uG5WYG4+6iZWcG5acjMrOCcCMzMCs6JwMys4JwIzMwKzonAzKzgnAjMzArOicDM\nrOCcCMzMCu7/AyDhoM98y/VJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9eb3462860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
